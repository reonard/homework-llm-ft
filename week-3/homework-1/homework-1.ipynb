{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c255ab52-589a-4b84-9046-6b8709ec840a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/anaconda3/envs/llm-ft/bin/python\n"
     ]
    }
   ],
   "source": [
    "! which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "970db398-c200-4399-8906-6b037e239abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05f08ff0-70bc-4fb1-95a1-23da8c6ba545",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d1bd168-e4c8-4178-b6d3-63b3edebc3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/app/huggingface/'\n",
    "os.environ['HF_HUB_CACHE'] = '/app/huggingface/hub'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb38fbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a70c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9f79249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.8616328835487366}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用默认的sentiment-analysis模型\n",
    "pipe = pipeline('sentiment-analysis')\n",
    "pipe('你好靓仔')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35f47d7b-d73c-4bcd-9c41-56ce86736292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998611211776733}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('you are so handsome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d9aee73-6669-44c6-971d-d3b0a021f450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'negative', 'score': 0.9997460246086121}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用自定义的sentiment-analysis模型\n",
    "pipe = pipeline('sentiment-analysis', model='bardsai/finance-sentiment-zh-base')\n",
    "pipe('股市暴跌，亏成狗了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a0c54a7-7059-4af3-ae45-c427540b7144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive', 'score': 0.9999748468399048}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('上涨10%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'neutral', 'score': 0.9999749660491943}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('你好帅')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 正常, with score: 0.9315885901451111\n"
     ]
    }
   ],
   "source": [
    "# 使用自定义的text-classification模型\n",
    "classifier = pipeline(\"text-classification\", model=\"alibaba-pai/pai-bert-base-zh-llm-risk-detection\", tokenizer=\"alibaba-pai/pai-bert-base-zh-llm-risk-detection\", max_length=128)\n",
    "predictions = classifier(\"你好帅\")\n",
    "for p in predictions:\n",
    "    print(f\"label: {p['label']}, with score: {p['score']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 低俗, with score: 0.5537309646606445\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier(\"约吗\")\n",
    "for p in predictions:\n",
    "    print(f\"label: {p['label']}, with score: {p['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "question_answerer = pipeline(task=\"question-answering\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9772, start: 38, end: 47, answer: Joe Biden\n"
     ]
    }
   ],
   "source": [
    "preds = question_answerer(\n",
    "    question=\"who's the president of the United States?\",\n",
    "    context=\"The president of the United States is Joe Biden.\"\n",
    ")\n",
    "print(\n",
    "    f\"score: {round(preds['score'], 4)}, start: {preds['start']}, end: {preds['end']}, answer: {preds['answer']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9736, start: 29, end: 35, answer: Sweden\n"
     ]
    }
   ],
   "source": [
    "preds = question_answerer(\n",
    "    question = \"Where do I live?\",\n",
    "    context = \"My name is Tim and I live in Sweden.\"\n",
    "    )\n",
    "print(\n",
    "    f\"score: {round(preds['score'], 4)}, start: {preds['start']}, end: {preds['end']}, answer: {preds['answer']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \" To be honest, I have never seen the salary I get from my family. When I come to my family, I ask myself whether I can give you a place to stay. I will report to you at any time. I have thought about it before. If I have such a experience in my career, I can follow a top entrepreneur. I don't do anything every day, just see how he opens up, what he says, what he does, it's all a very happy thing.\"}\n",
      "{'text': \" To be honest, I have never seen the salary card that Ge Li gave me. When I came to Ge Li, I asked if Mr. Dong could give me a room near your office. I will report to you at any time. I once imagined that if I had such an experience in my career, I could be with a top entrepreneur. I would do anything every day, just watch him have a meeting, listen to him, and do anything. It's a very happy thing.\"}\n"
     ]
    }
   ],
   "source": [
    "# 语音识别，格力之虎， wisper-small\n",
    "transcriber = pipeline(task=\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
    "text = transcriber(\"/app/ai/Wav2Lip/inputs/gelitiger.wav\")\n",
    "print(text)\n",
    "\n",
    "# 语音识别，格力之虎，wisper-medium\n",
    "transcriber = pipeline(task=\"automatic-speech-recognition\", model=\"openai/whisper-medium\")\n",
    "text = transcriber(\"/app/ai/Wav2Lip/inputs/gelitiger.wav\")\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
